{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 基于CNN模型的物体识别\n",
    "\n",
    "## 1.复习上课内容以及复现课程代码\n",
    "\n",
    "在本部分，你需要复习上课内容和课程代码后，自己复现课程代码。\n",
    "\n",
    "## 2.回答以下理论题目?\n",
    "\n",
    "### 2.1. Suppose your input is a 100 by 100 gray image, and you use a convolutional layer with 50 filters that are each 5x5. How many parameters does this hidden layer have (including the bias parameters)? \n",
    "\n",
    "#### $\\color{blue}{Answer:（5*5+1）*50=1300}$\n",
    "\n",
    "### 2.2. What are \"local invariant\" and \"parameter sharing\" ?\n",
    "#### $\\color{blue}{local invariant:局部不变特征}$\n",
    "#### $\\color{blue}{parameter sharing:权值共享}$\n",
    "##### $\\color{blue}{（权值共享）从一个局部区域学习到的信息，应用到图像的其它地方。\n",
    "即用一个相同的卷积核去卷积整幅图像，相当于对图像做一个全图滤波。\n",
    "一个卷积核对应的特征比如是边缘，那么用该卷积核去对图像做全图滤波，即是将图像各个位置的边缘都滤出来。\n",
    "（帮助实现不变性）。不同的特征靠多个不同的卷积核实现。}$\n",
    "##### $\\color{blue}{（局部不变特征）图像的局部统计特征在整幅图像上具有重复性（即位置无关性）。\n",
    "即如果图像中存在某个基本图形，该基本图形可能出现在任意位置，那么不同位置共享相同权值可实现在数据的不同位置检测相同的模式。\n",
    "比如我们在第一个窗口卷积后得到的特征是边缘，那么这个卷积核对应的就是边缘特征的提取方式，那么我们就可以用这个卷积核去提取其它区域的边缘特征。}$\n",
    "\n",
    "### 2.3. Why we use batch normalization ?\n",
    "##### $\\color{blue}{为什么要归一化？因为不做归一化，不同的特征具有不同数量级的数据，数量级大的特征影响更大。进一步体现在损失函数上，feature scaling之前，损失函数的切面图是椭圆的，之后就变成圆，无论优化算法在何处开始，都更容易收敛到最优解，避免了很多弯路。尤其是在神经网络中，特征经过线性组合后，还要经过激活函数，如果某个特征数量级过大，在经过激活函数时，就会提前进入它的饱和区间，即不管如何增大这个数值，它的激活函数值都在 1 附近，不会有太大变化，这样激活函数就对这个特征不敏感。在神经网络用 SGD 等算法进行优化时，不同量纲的数据会使网络失衡，很不稳定。在神经网络中，这个问题不仅发生在输入层，也发生在隐藏层，因为前一层的输出值，对后面一层来说，就是它的输入，而且也要经过激活函数，所以就需要做 batch normalization，就是在前一层的线性输出 z 上做 normalization：需要求出这一 batch 数据的平均值和标准差，然后再经过激活函数，进入到下一层。}$\n",
    "\n",
    "### 2.4. What problem does dropout try to solve ?\n",
    "##### $\\color{blue}{防止过拟合}$\n",
    "\n",
    "## 3. 实践题\n",
    "\n",
    "### 3.1 In the first session of the practical part, you will implement an image classification model using any deep learning libraries that you are familiar with,  which means, except for tensorflow and keras, you can also use pytorch/caffe/... .  The dataset used in this session is the cifar10 which contains 50000 color (RGB) images, each with size 32x32x3.  All 50000 images are classified into ten categories. \n",
    "\n",
    "##### It is your time to build your model. Try your best to build a model with good performance on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义超参\n",
    "EPOCH = 2\n",
    "BATCH_SIZE = 64\n",
    "lr = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载数据\n",
    "train_data = datasets.CIFAR10(root='./data',train=True,\n",
    "                             transform=transforms.ToTensor(),download=False)\n",
    "test_data = datasets.CIFAR10(root='./data',train=False,\n",
    "                            transform=transforms.ToTensor(),download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#数据分批\n",
    "train_loader = DataLoader(dataset=train_data,batch_size=BATCH_SIZE,shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_data,batch_size=BATCH_SIZE,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#使用pytorch内置模型DenseNet\n",
    "model = models.densenet121(pretrained=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#设置损失函数和优化函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:30,epoch:0,loss:1.7478\n",
      "i:60,epoch:0,loss:1.7618\n",
      "i:90,epoch:0,loss:1.9229\n",
      "i:120,epoch:0,loss:1.5330\n",
      "i:150,epoch:0,loss:1.5660\n",
      "i:180,epoch:0,loss:1.4621\n",
      "i:210,epoch:0,loss:1.4829\n",
      "i:240,epoch:0,loss:1.3796\n",
      "i:270,epoch:0,loss:1.3532\n",
      "i:300,epoch:0,loss:1.6536\n",
      "i:330,epoch:0,loss:1.3436\n",
      "i:360,epoch:0,loss:1.3088\n",
      "i:390,epoch:0,loss:1.3261\n",
      "i:420,epoch:0,loss:1.4839\n",
      "i:450,epoch:0,loss:1.1727\n",
      "i:480,epoch:0,loss:1.1294\n",
      "i:510,epoch:0,loss:1.6539\n",
      "i:540,epoch:0,loss:1.1720\n",
      "i:570,epoch:0,loss:1.3422\n",
      "i:600,epoch:0,loss:1.1104\n",
      "i:630,epoch:0,loss:1.0515\n",
      "i:660,epoch:0,loss:1.1519\n",
      "i:690,epoch:0,loss:1.0400\n",
      "i:720,epoch:0,loss:1.1184\n",
      "i:750,epoch:0,loss:1.2436\n",
      "i:780,epoch:0,loss:0.9997\n",
      "i:30,epoch:1,loss:0.8343\n",
      "i:60,epoch:1,loss:0.9428\n",
      "i:90,epoch:1,loss:0.9946\n",
      "i:120,epoch:1,loss:1.1810\n",
      "i:150,epoch:1,loss:1.3908\n",
      "i:180,epoch:1,loss:0.8470\n",
      "i:210,epoch:1,loss:0.8614\n",
      "i:240,epoch:1,loss:1.1940\n",
      "i:270,epoch:1,loss:1.1707\n",
      "i:300,epoch:1,loss:0.9650\n",
      "i:330,epoch:1,loss:1.0422\n",
      "i:360,epoch:1,loss:1.0225\n",
      "i:390,epoch:1,loss:1.2758\n",
      "i:420,epoch:1,loss:0.9847\n",
      "i:450,epoch:1,loss:1.0871\n",
      "i:480,epoch:1,loss:0.8825\n",
      "i:510,epoch:1,loss:1.0842\n",
      "i:540,epoch:1,loss:0.9925\n",
      "i:570,epoch:1,loss:0.8988\n",
      "i:600,epoch:1,loss:1.0717\n",
      "i:630,epoch:1,loss:0.8948\n",
      "i:660,epoch:1,loss:0.9024\n",
      "i:690,epoch:1,loss:1.2980\n",
      "i:720,epoch:1,loss:0.8178\n",
      "i:750,epoch:1,loss:0.8384\n",
      "i:780,epoch:1,loss:0.8740\n"
     ]
    }
   ],
   "source": [
    "#训练\n",
    "for epoch in range(EPOCH):\n",
    "    for i,data in enumerate(train_loader):\n",
    "        inputs,labels = data\n",
    "        #forward\n",
    "        outputs = model(inputs)\n",
    "        #loss\n",
    "        loss = criterion(outputs,labels)\n",
    "        #optim zero_grad\n",
    "        optimizer.zero_grad()\n",
    "        #backward\n",
    "        loss.backward()\n",
    "        #update\n",
    "        optimizer.step()\n",
    "        if i%30==29:\n",
    "            print(\"i:{},epoch:{},loss:{:.4f}\".format(i+1,epoch,loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cifar10_densenet121 saved\n"
     ]
    }
   ],
   "source": [
    "#保存模型\n",
    "torch.save(model,\"cifar10_densenet121.pt\")\n",
    "print(\"cifar10_densenet121 saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  2.1603,  -1.4474,   5.1433,  ...,  -6.8338,  -6.4777,  -5.7651],\n",
      "        [  1.2352,   2.9728,   7.0455,  ..., -13.0346, -13.1349, -12.1516],\n",
      "        [  0.5995,   3.6988,   1.8783,  ...,  -7.5147,  -7.0946,  -6.6891],\n",
      "        ...,\n",
      "        [  4.4432,   6.0482,   1.4342,  ...,  -8.9117,  -7.8043,  -7.8251],\n",
      "        [  2.1964,  -1.9868,   5.5197,  ...,  -7.2866,  -7.0002,  -6.5239],\n",
      "        [  2.3356,  -1.3644,   4.3710,  ...,  -9.0622,  -8.6308,  -7.7677]],\n",
      "       grad_fn=<AddmmBackward>)\n",
      "tensor([[  2.7750,   2.2089,   2.6837,  ...,  -7.8354,  -7.2944,  -6.9703],\n",
      "        [  1.4201,  -0.5061,   6.0062,  ...,  -8.0113,  -7.4115,  -7.0700],\n",
      "        [  4.6798,  10.3462,   2.6835,  ..., -13.1156, -12.2545, -11.3196],\n",
      "        ...,\n",
      "        [ 10.3972,   2.1791,   5.3806,  ...,  -9.2449,  -8.7958,  -8.4116],\n",
      "        [ 13.7159,  10.9192,   9.8328,  ..., -23.0810, -22.0185, -20.6065],\n",
      "        [  4.5631,  -2.0598,   7.5964,  ...,  -8.0467,  -7.8516,  -7.2575]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    }
   ],
   "source": [
    "#测试\n",
    "model = torch.load(\"cifar10_densenet121.pt\")\n",
    "correct,total = 0,0\n",
    "for i,data in enumerate(test_loader):\n",
    "    inputs,labels = data\n",
    "    #forward\n",
    "    outputs = model(inputs)\n",
    "    _,predicted = torch.max(outputs.data,1)\n",
    "    total+=labels.size(0)\n",
    "    correct+=(predicted==labels).sum().item()\n",
    "print(\"10000张测试图像的准确率:{:.4f}\".format(100.0*correct/total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
